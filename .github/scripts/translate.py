#!/usr/bin/env python3
"""
è‡ªåŠ¨ç¿»è¯‘è„šæœ¬ - ä½¿ç”¨DeepSeek APIè¿›è¡Œå¤šè¯­è¨€ç¿»è¯‘
"""

import os
import sys
import json
import requests
import time
import subprocess
import re
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set
from dataclasses import dataclass
from enum import Enum
import logging
from datetime import datetime

# é…ç½®è¯¦ç»†æ—¥å¿—
log_file_handler = logging.FileHandler('translation.log', encoding='utf-8')
log_file_handler.setLevel(logging.INFO)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        log_file_handler
    ],
    force=True
)
logger = logging.getLogger(__name__)

def flush_logs():
    """å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ—¥å¿—å¤„ç†å™¨"""
    for handler in logging.getLogger().handlers:
        handler.flush()

def close_logs():
    """å…³é—­æ‰€æœ‰æ—¥å¿—å¤„ç†å™¨"""
    for handler in logging.getLogger().handlers:
        if hasattr(handler, 'close'):
            handler.close()

@dataclass
class KeyChange:
    """é”®å€¼å¯¹å˜æ›´ä¿¡æ¯"""
    key: str
    old_value: Optional[str]
    new_value: Optional[str]
    operation: str  # 'added', 'deleted', 'modified'

@dataclass
class FileChanges:
    """æ–‡ä»¶å˜æ›´ä¿¡æ¯"""
    namespace: str
    file_path: str
    added_keys: List[KeyChange]
    deleted_keys: List[KeyChange]
    modified_keys: List[KeyChange]

class ChangeType(Enum):
    """å˜æ›´ç±»å‹æšä¸¾"""
    ADDED = "added"
    DELETED = "deleted"
    MODIFIED = "modified"

# æ£€æµ‹æ˜¯å¦åœ¨GitHub Actionsç¯å¢ƒä¸­è¿è¡Œ
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'

def log_progress(message: str, level: str = "info"):
    """ç»Ÿä¸€çš„è¿›åº¦æ—¥å¿—å‡½æ•°ï¼Œåœ¨GitHub Actionsä¸­ä½¿ç”¨ç‰¹æ®Šæ ¼å¼"""
    timestamp = datetime.now().strftime("%H:%M:%S")

    if IS_GITHUB_ACTIONS:
        # GitHub Actions ç‰¹æ®Šæ ¼å¼
        if level == "error":
            print(f"::error::{message}")
        elif level == "warning":
            print(f"::warning::{message}")
        else:
            print(f"::notice::[{timestamp}] {message}")
    else:
        # æ ‡å‡†æ—¥å¿—è¾“å‡ºï¼ˆä»…åœ¨éGitHub Actionsç¯å¢ƒä¸­ï¼‰
        if level == "error":
            logger.error(message)
        elif level == "warning":
            logger.warning(message)
        else:
            logger.info(message)

    # å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒº
    sys.stdout.flush()

def log_section(title: str):
    """è®°å½•ä¸»è¦ç« èŠ‚ï¼Œåœ¨GitHub Actionsä¸­ä½¿ç”¨åˆ†ç»„"""
    if IS_GITHUB_ACTIONS:
        print(f"::group::{title}")
    log_progress(f"=== {title} ===")

def log_section_end():
    """ç»“æŸç« èŠ‚åˆ†ç»„"""
    if IS_GITHUB_ACTIONS:
        print("::endgroup::")

class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""
    def __init__(self, total_languages: int, total_namespaces: int):
        self.total_languages = total_languages
        self.total_namespaces = total_namespaces
        self.current_language = 0
        self.current_namespace = 0
        self.start_time = time.time()

    def start_language(self, lang_code: str, lang_name: str):
        self.current_language += 1
        self.current_namespace = 0
        elapsed = time.time() - self.start_time
        log_section(f"è¯­è¨€ {self.current_language}/{self.total_languages}: {lang_code} ({lang_name}) - å·²ç”¨æ—¶ {elapsed:.1f}s")

    def start_namespace(self, namespace: str):
        self.current_namespace += 1
        log_progress(f"  å‘½åç©ºé—´ {self.current_namespace}/{self.total_namespaces}: {namespace}")

    def log_batch_progress(self, batch_num: int, total_batches: int, batch_size: int):
        log_progress(f"    æ‰¹æ¬¡ {batch_num}/{total_batches} (æ¯æ‰¹ {batch_size} ä¸ªé”®)")

    def finish_language(self):
        log_section_end()

    def get_total_progress(self) -> str:
        total_tasks = self.total_languages * self.total_namespaces
        completed_tasks = (self.current_language - 1) * self.total_namespaces + self.current_namespace
        percentage = (completed_tasks / total_tasks) * 100 if total_tasks > 0 else 0
        elapsed = time.time() - self.start_time
        return f"æ€»è¿›åº¦: {completed_tasks}/{total_tasks} ({percentage:.1f}%) - å·²ç”¨æ—¶ {elapsed:.1f}s"

# é…ç½®
DEEPSEEK_API_URL = "https://api.deepseek.com/chat/completions"
ASSETS_DIR = "Localization-Resource-Pack/assets"
TRANSLATE_DIR = "translate"
SYSTEM_PROMPT_FILE = "Localization-Resource-Pack/assets/system_prompt.md"
USER_PROMPT_FILE = "Localization-Resource-Pack/assets/user_prompt.md"

# ç›®æ ‡è¯­è¨€åˆ—è¡¨ï¼ˆåŸºäºä¹‹å‰çš„æ¨èï¼‰
TARGET_LANGUAGES = {
    "en_us": "English (US)",
    "pt_br": "Portuguese (Brazil)",
    "ru_ru": "Russian",
    "de_de": "German",
    "es_es": "Spanish (Spain)",
    "es_mx": "Spanish (Mexico)",
    "fr_fr": "French (France)",
    "fr_ca": "French (Canada)",
    "tr_tr": "Turkish",
    "ja_jp": "Japanese",
    "ko_kr": "Korean",
    "pl_pl": "Polish",
    "nl_nl": "Dutch",
    "it_it": "Italian",
    "id_id": "Indonesian",
    "vi_vn": "Vietnamese",
    "zh_tw": "Traditional Chinese (Taiwan)",
    "zh_hk": "Traditional Chinese (Hong Kong)"
}

class DeepSeekTranslator:
    def __init__(self, api_key: str, non_thinking_mode: bool = False):
        self.api_key = api_key
        self.non_thinking_mode = non_thinking_mode
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        self._init_error_logging()
        self.system_prompt = self._load_prompt_template(SYSTEM_PROMPT_FILE)
        self.user_prompt = self._load_prompt_template(USER_PROMPT_FILE)

    def _init_error_logging(self):
        """åˆå§‹åŒ–é”™è¯¯æ—¥å¿—ç³»ç»Ÿ"""
        log_dir = os.path.join(os.path.dirname(__file__), "logs")
        os.makedirs(log_dir, exist_ok=True)
        
        # åˆ›å»ºæ–°çš„é”™è¯¯æ±‡æ€»æ—¥å¿—æ–‡ä»¶
        summary_file = os.path.join(log_dir, "error_summary.log")
        session_start = datetime.now().isoformat()
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"ç¿»è¯‘é”™è¯¯æ±‡æ€»æ—¥å¿—\n")
            f.write(f"ä¼šè¯å¼€å§‹æ—¶é—´: {session_start}\n")
            f.write(f"æ¨¡å¼: {'éæ€è€ƒæ¨¡å¼' if self.non_thinking_mode else 'æ€è€ƒæ¨¡å¼'}\n")
            f.write("=" * 80 + "\n\n")

    def _load_prompt_template(self, file_path: str) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿æ–‡ä»¶ï¼Œè·³è¿‡æ ‡é¢˜è¡Œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            # è·³è¿‡ä»¥ # å¼€å¤´çš„æ ‡é¢˜è¡Œå’Œç©ºè¡Œ
            content_lines = []
            for line in lines:
                stripped_line = line.strip()
                # è·³è¿‡æ ‡é¢˜è¡Œï¼ˆä»¥#å¼€å¤´ï¼‰å’Œç©ºè¡Œï¼Œä½†ä¿ç•™å†…å®¹å¼€å§‹åçš„ç©ºè¡Œ
                if content_lines or (stripped_line and not stripped_line.startswith('#')):
                    content_lines.append(line)

            return ''.join(content_lines).strip()
        except FileNotFoundError:
            log_progress(f"è­¦å‘Šï¼šæç¤ºè¯æ¨¡æ¿æ–‡ä»¶ {file_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯", "warning")
            return ""
        except Exception as e:
            log_progress(f"è­¦å‘Šï¼šåŠ è½½æç¤ºè¯æ¨¡æ¿ {file_path} æ—¶å‡ºé”™: {e}", "warning")
            return ""

    def _format_prompt(self, template: str, **kwargs) -> str:
        """æ ¼å¼åŒ–æç¤ºè¯æ¨¡æ¿ï¼Œæ›¿æ¢å˜é‡"""
        try:
            # ä½¿ç”¨åŒå¤§æ‹¬å·æ ¼å¼è¿›è¡Œå˜é‡æ›¿æ¢
            formatted = template
            for key, value in kwargs.items():
                formatted = formatted.replace(f"{{{{{key}}}}}", str(value))
            return formatted
        except Exception as e:
            log_progress(f"è­¦å‘Šï¼šæ ¼å¼åŒ–æç¤ºè¯æ—¶å‡ºé”™: {e}", "warning")
            return template

    def validate_placeholder_consistency(self, original_text: str, translated_text: str) -> bool:
        """éªŒè¯ç¿»è¯‘å‰åçš„å ä½ç¬¦ä¸€è‡´æ€§

        åªæ£€æŸ¥æœ‰æ•ˆçš„æœ¬åœ°åŒ–å‚æ•°æ ¼å¼ï¼š%s å’Œ %n$s
        """
        # åŒ¹é… %s å’Œ %n$s æ ¼å¼çš„å ä½ç¬¦
        placeholder_pattern = r'%(?:\d+\$)?s'

        original_placeholders = re.findall(placeholder_pattern, original_text)
        translated_placeholders = re.findall(placeholder_pattern, translated_text)

        # æ’åºåæ¯”è¾ƒï¼Œç¡®ä¿å ä½ç¬¦å®Œå…¨ä¸€è‡´
        return sorted(original_placeholders) == sorted(translated_placeholders)

    def validate_translation_result(self, original: Dict[str, str], translated: Dict[str, str]) -> List[str]:
        """éªŒè¯ç¿»è¯‘ç»“æœçš„å®Œæ•´æ€§å’Œæ ¼å¼æ­£ç¡®æ€§

        Returns:
            List[str]: é”™è¯¯ä¿¡æ¯åˆ—è¡¨ï¼Œç©ºåˆ—è¡¨è¡¨ç¤ºéªŒè¯é€šè¿‡
        """
        errors = []

        # 1. æ£€æŸ¥é”®å®Œæ•´æ€§
        original_keys = set(original.keys())
        translated_keys = set(translated.keys())

        if original_keys != translated_keys:
            missing_keys = original_keys - translated_keys
            extra_keys = translated_keys - original_keys

            if missing_keys:
                errors.append(f"ç¼ºå°‘é”®: {list(missing_keys)}")
            if extra_keys:
                errors.append(f"å¤šä½™é”®: {list(extra_keys)}")

        # 2. æ£€æŸ¥å€¼ç±»å‹å’Œå ä½ç¬¦ä¸€è‡´æ€§
        for key in original_keys & translated_keys:
            translated_value = translated.get(key)

            if not isinstance(translated_value, str):
                errors.append(f"é”® '{key}' çš„å€¼ä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹: {type(translated_value)}")
                continue

            # æ£€æŸ¥å ä½ç¬¦ä¸€è‡´æ€§ï¼ˆå…è®¸ç©ºå€¼ï¼‰
            original_value = original[key]
            if not self.validate_placeholder_consistency(original_value, translated_value):
                errors.append(f"é”® '{key}' çš„å ä½ç¬¦ä¸ä¸€è‡´: '{original_value}' -> '{translated_value}'")

        return errors

    def log_translation_failure(self, attempt: int, system_prompt: str, user_prompt: str,
                              api_response: str, error: str, texts: Dict[str, str]) -> None:
        """è®°å½•ç¿»è¯‘å¤±è´¥çš„è¯¦ç»†ä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶"""
        log_dir = os.path.join(os.path.dirname(__file__), "logs")
        os.makedirs(log_dir, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # åŒ…å«æ¯«ç§’
        log_file = os.path.join(log_dir, f"translation_failure_{timestamp}_attempt_{attempt}.log")

        # è¯¦ç»†é”™è¯¯æ—¥å¿—
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"ç¿»è¯‘å¤±è´¥æ—¥å¿— - å°è¯•æ¬¡æ•°: {attempt}\n")
            f.write(f"æ—¶é—´: {datetime.now().isoformat()}\n")
            f.write(f"æ–‡æœ¬æ•°é‡: {len(texts)}\n")
            f.write("=" * 80 + "\n\n")

            f.write(f"é”™è¯¯ä¿¡æ¯:\n{error}\n")
            f.write("\n" + "=" * 80 + "\n\n")

            f.write("åŸå§‹æ–‡æœ¬:\n")
            f.write(json.dumps(texts, ensure_ascii=False, indent=2))
            f.write("\n\n" + "=" * 80 + "\n\n")

            f.write("ç³»ç»Ÿæç¤ºè¯:\n")
            f.write(system_prompt)
            f.write("\n\n" + "=" * 80 + "\n\n")

            f.write("ç”¨æˆ·æç¤ºè¯:\n")
            f.write(user_prompt)
            f.write("\n\n" + "=" * 80 + "\n\n")

            f.write("APIå“åº”:\n")
            f.write(api_response)
            f.write("\n\n" + "=" * 80 + "\n")

        # é”™è¯¯æ±‡æ€»æ—¥å¿—
        summary_file = os.path.join(log_dir, "error_summary.log")
        with open(summary_file, 'a', encoding='utf-8') as f:
            f.write(f"[{datetime.now().isoformat()}] å°è¯• {attempt} å¤±è´¥: {error[:100]}{'...' if len(error) > 100 else ''}\n")
            f.write(f"  æ–‡ä»¶: {os.path.basename(log_file)}\n")
            f.write(f"  æ–‡æœ¬æ•°é‡: {len(texts)}\n\n")

        log_progress(f"ç¿»è¯‘å¤±è´¥æ—¥å¿—å·²ä¿å­˜: {log_file}", "warning")
        flush_logs()  # ç¡®ä¿é”™è¯¯æ—¥å¿—è¢«åŠæ—¶å†™å…¥

    def translate_batch(self, texts: Dict[str, str], target_lang: str, target_lang_name: str) -> Dict[str, str]:
        """
        ç¿»è¯‘ä¸€æ‰¹æ–‡æœ¬ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶å’Œå®Œæ•´æ€§éªŒè¯
        """
        max_retries = 3

        if not texts:
            return {}

        source_text = json.dumps(texts, ensure_ascii=False, indent=2)
        log_progress(f"      å¼€å§‹ç¿»è¯‘ {len(texts)} ä¸ªé”®åˆ° {target_lang_name}")

        for attempt in range(max_retries):
            try:
                log_progress(f"      å°è¯• {attempt + 1}/{max_retries}")

                # ä½¿ç”¨æç¤ºè¯æ¨¡æ¿æˆ–å›é€€åˆ°é»˜è®¤æç¤ºè¯
                if self.system_prompt:
                    system_prompt = self._format_prompt(
                        self.system_prompt,
                        source_language="ä¸­æ–‡",
                        target_language=target_lang_name
                    )
                    log_progress(f"      ä½¿ç”¨è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ (é•¿åº¦: {len(system_prompt)} å­—ç¬¦)")
                else:
                    system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¸¸æˆæœ¬åœ°åŒ–ç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿Minecraftç›¸å…³å†…å®¹çš„ç¿»è¯‘ã€‚"
                    log_progress(f"      ä½¿ç”¨é»˜è®¤ç³»ç»Ÿæç¤ºè¯")

                if self.user_prompt:
                    user_prompt = self._format_prompt(
                        self.user_prompt,
                        source_language="ä¸­æ–‡",
                        target_language=target_lang_name,
                        content_to_translate=source_text
                    )
                    log_progress(f"      ä½¿ç”¨è‡ªå®šä¹‰ç”¨æˆ·æç¤ºè¯ (é•¿åº¦: {len(user_prompt)} å­—ç¬¦)")
                else:
                    user_prompt = f"""è¯·å°†ä»¥ä¸‹JSONæ ¼å¼çš„ä¸­æ–‡æ¸¸æˆæœ¬åœ°åŒ–æ–‡æœ¬ç¿»è¯‘ä¸º{target_lang_name}ã€‚

è¦æ±‚ï¼š
1. ä¿æŒJSONæ ¼å¼ä¸å˜ï¼Œåªç¿»è¯‘å€¼éƒ¨åˆ†
2. ä¿æŒæ¸¸æˆæœ¯è¯­çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§
3. è€ƒè™‘æ¸¸æˆä¸Šä¸‹æ–‡ï¼Œä½¿ç¿»è¯‘è‡ªç„¶æµç•…
4. ä¿æŒåŸæœ‰çš„æ ¼å¼æ ‡è®°ï¼ˆå¦‚æ–¹æ‹¬å·ã€å†’å·ç­‰ï¼‰
5. å¯¹äºä¸“æœ‰åè¯ï¼ˆå¦‚"æ•°æ®åŒ…"ã€"å®ä½“"ç­‰ï¼‰ï¼Œä½¿ç”¨æ¸¸æˆä¸­çš„æ ‡å‡†ç¿»è¯‘

æºæ–‡æœ¬ï¼š
{source_text}

è¯·ç›´æ¥è¿”å›ç¿»è¯‘åçš„JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—ã€‚"""
                    log_progress(f"      ä½¿ç”¨é»˜è®¤ç”¨æˆ·æç¤ºè¯")

                # æ ¹æ®æ¨¡å¼é€‰æ‹©æ¨¡å‹
                model = "deepseek-chat" if self.non_thinking_mode else "deepseek-reasoner"
                log_progress(f"      ä½¿ç”¨æ¨¡å‹: {model} ({'éæ€è€ƒæ¨¡å¼' if self.non_thinking_mode else 'æ€è€ƒæ¨¡å¼'})")

                payload = {
                    "model": model,
                    "messages": [
                        {
                            "role": "system",
                            "content": system_prompt
                        },
                        {
                            "role": "user",
                            "content": user_prompt
                        }
                    ],
                    "temperature": 1.3,
                    "stream": False
                }

                # è°ƒç”¨API
                log_progress(f"      å‘é€APIè¯·æ±‚åˆ°DeepSeek...")
                start_time = time.time()
                response = requests.post(DEEPSEEK_API_URL, headers=self.headers, json=payload, timeout=60)
                api_time = time.time() - start_time
                log_progress(f"      APIå“åº”æ—¶é—´: {api_time:.2f}s, çŠ¶æ€ç : {response.status_code}")

                response.raise_for_status()

                result = response.json()
                translated_content = result["choices"][0]["message"]["content"].strip()
                log_progress(f"      æ”¶åˆ°ç¿»è¯‘å“åº” (é•¿åº¦: {len(translated_content)} å­—ç¬¦)")

                # æ¸…ç†å“åº”å†…å®¹
                original_content = translated_content
                if translated_content.startswith("```json"):
                    translated_content = translated_content[7:]
                if translated_content.startswith("```"):
                    translated_content = translated_content[3:]
                if translated_content.endswith("```"):
                    translated_content = translated_content[:-3]
                translated_content = translated_content.strip()

                if original_content != translated_content:
                    log_progress(f"      æ¸…ç†ä»£ç å—æ ‡è®°åé•¿åº¦: {len(translated_content)} å­—ç¬¦")

                # è§£æJSON
                try:
                    log_progress(f"      è§£æJSONå“åº”...")
                    translated_dict = json.loads(translated_content)
                    log_progress(f"      JSONè§£ææˆåŠŸï¼ŒåŒ…å« {len(translated_dict)} ä¸ªé”®")
                except json.JSONDecodeError as e:
                    raise ValueError(f"JSONè§£æå¤±è´¥: {e}")

                # éªŒè¯ç¿»è¯‘ç»“æœ
                log_progress(f"      éªŒè¯ç¿»è¯‘ç»“æœ...")
                validation_errors = self.validate_translation_result(texts, translated_dict)
                if validation_errors:
                    log_progress(f"      éªŒè¯å¤±è´¥: {'; '.join(validation_errors)}", "warning")
                    raise ValueError(f"ç¿»è¯‘éªŒè¯å¤±è´¥: {'; '.join(validation_errors)}")

                # éªŒè¯æˆåŠŸï¼Œè¿”å›ç»“æœ
                log_progress(f"      ç¿»è¯‘æˆåŠŸï¼å°è¯•æ¬¡æ•°: {attempt + 1}, æ€»è€—æ—¶: {time.time() - start_time:.2f}s")
                return translated_dict

            except Exception as e:
                error_msg = f"ç¿»è¯‘å°è¯• {attempt + 1} å¤±è´¥: {str(e)}"
                log_progress(error_msg, "error")

                # è®°å½•å¤±è´¥è¯¦æƒ…
                self.log_translation_failure(
                    attempt=attempt + 1,
                    system_prompt=system_prompt if 'system_prompt' in locals() else "æœªç”Ÿæˆ",
                    user_prompt=user_prompt if 'user_prompt' in locals() else "æœªç”Ÿæˆ",
                    api_response=translated_content if 'translated_content' in locals() else "æ— å“åº”",
                    error=str(e),
                    texts=texts
                )

                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´
                    log_progress(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè¿”å›ç©ºå­—å…¸
                    log_progress(f"ç¿»è¯‘å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {str(e)}", "error")
                    return {}

def get_git_changes() -> List[FileChanges]:
    """è·å–Gitå˜æ›´ï¼Œæ£€æµ‹æºç¿»è¯‘æ–‡ä»¶çš„å˜åŒ–"""
    try:
        # è·å–æœ€æ–°æäº¤çš„å˜æ›´æ–‡ä»¶åˆ—è¡¨
        result = subprocess.run([
            'git', 'diff', '--name-only', 'HEAD~1', 'HEAD'
        ], capture_output=True, text=True, cwd='.')

        if result.returncode != 0:
            log_progress("æ— æ³•è·å–Gitå·®å¼‚ï¼Œä½¿ç”¨å…¨é‡ç¿»è¯‘æ¨¡å¼", "warning")
            return []

        changed_files = result.stdout.strip().split('\n') if result.stdout.strip() else []
        log_progress(f"æ£€æµ‹åˆ° {len(changed_files)} ä¸ªå˜æ›´æ–‡ä»¶")

        file_changes = []

        for file_path in changed_files:
            # åªå¤„ç†æºç¿»è¯‘æ–‡ä»¶ (en_us.json)
            if not file_path.endswith('/lang/en_us.json'):
                continue

            # æå–å‘½åç©ºé—´
            parts = file_path.split('/')
            if len(parts) < 4 or 'assets' not in parts:
                continue

            assets_index = parts.index('assets')
            if assets_index + 1 >= len(parts):
                continue

            namespace = parts[assets_index + 1]

            # è·å–æ–‡ä»¶çš„å…·ä½“å˜æ›´
            changes = get_file_key_changes(file_path)
            if changes:
                file_changes.append(FileChanges(
                    namespace=namespace,
                    file_path=file_path,
                    added_keys=changes['added'],
                    deleted_keys=changes['deleted'],
                    modified_keys=changes['modified']
                ))

        return file_changes

    except Exception as e:
        log_progress(f"Gitå·®å¼‚æ£€æµ‹å¤±è´¥: {e}", "error")
        return []

def get_file_key_changes(file_path: str) -> Optional[Dict[str, List[KeyChange]]]:
    """è·å–å•ä¸ªæ–‡ä»¶çš„é”®å€¼å¯¹å˜æ›´"""
    try:
        # è·å–æ—§ç‰ˆæœ¬æ–‡ä»¶å†…å®¹
        old_content_result = subprocess.run([
            'git', 'show', f'HEAD~1:{file_path}'
        ], capture_output=True, text=True, cwd='.')

        old_data = {}
        if old_content_result.returncode == 0:
            try:
                old_data = json.loads(old_content_result.stdout)
            except json.JSONDecodeError:
                pass

        # è·å–æ–°ç‰ˆæœ¬æ–‡ä»¶å†…å®¹
        new_data = {}
        if os.path.exists(file_path):
            new_data = load_json_file(file_path) or {}

        # æ¯”è¾ƒå˜æ›´
        old_keys = set(old_data.keys())
        new_keys = set(new_data.keys())

        added_keys = []
        deleted_keys = []
        modified_keys = []

        # æ·»åŠ çš„é”®
        for key in new_keys - old_keys:
            added_keys.append(KeyChange(
                key=key,
                old_value=None,
                new_value=new_data[key],
                operation=ChangeType.ADDED.value
            ))

        # åˆ é™¤çš„é”®
        for key in old_keys - new_keys:
            deleted_keys.append(KeyChange(
                key=key,
                old_value=old_data[key],
                new_value=None,
                operation=ChangeType.DELETED.value
            ))

        # ä¿®æ”¹çš„é”®
        for key in old_keys & new_keys:
            if old_data[key] != new_data[key]:
                modified_keys.append(KeyChange(
                    key=key,
                    old_value=old_data[key],
                    new_value=new_data[key],
                    operation=ChangeType.MODIFIED.value
                ))

        return {
            'added': added_keys,
            'deleted': deleted_keys,
            'modified': modified_keys
        }

    except Exception as e:
        log_progress(f"è·å–æ–‡ä»¶å˜æ›´å¤±è´¥ {file_path}: {e}", "error")
        return None

def load_json_file(file_path: str) -> Optional[Dict[str, str]]:
    """åŠ è½½JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        log_progress(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}", "warning")
        return None
    except json.JSONDecodeError as e:
        log_progress(f"JSONè§£æé”™è¯¯ {file_path}: {e}", "error")
        return None

def save_json_file(file_path: str, data: Dict[str, str]) -> bool:
    """ä¿å­˜JSONæ–‡ä»¶"""
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        log_progress(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {file_path}: {e}", "error")
        return False

def merge_translations(base_dict: Dict[str, str], override_dict: Dict[str, str]) -> Dict[str, str]:
    """åˆå¹¶ç¿»è¯‘ï¼Œoverride_dictä¸­çš„å†…å®¹ä¼šè¦†ç›–base_dictä¸­çš„å¯¹åº”å†…å®¹"""
    result = base_dict.copy()
    result.update(override_dict)
    return result

def get_namespace_list() -> List[str]:
    """è·å–æ‰€æœ‰å‘½åç©ºé—´åˆ—è¡¨"""
    namespaces = []
    assets_dir = Path(ASSETS_DIR)
    if assets_dir.exists():
        for namespace_dir in assets_dir.iterdir():
            if namespace_dir.is_dir() and namespace_dir.name not in ['system_prompt.md', 'user_prompt.md']:
                lang_dir = namespace_dir / "lang"
                if lang_dir.exists():
                    namespaces.append(namespace_dir.name)
    return namespaces

def load_namespace_translations(namespace: str, lang_code: str) -> Dict[str, str]:
    """åŠ è½½æŒ‡å®šå‘½åç©ºé—´çš„ç¿»è¯‘"""
    # å…ˆå°è¯•ä»assetsç›®å½•åŠ è½½
    assets_file = Path(ASSETS_DIR) / namespace / "lang" / f"{lang_code}.json"
    if assets_file.exists():
        return load_json_file(str(assets_file)) or {}

    # å†å°è¯•ä»translateç›®å½•åŠ è½½
    translate_file = Path(TRANSLATE_DIR) / namespace / "lang" / f"{lang_code}.json"
    if translate_file.exists():
        return load_json_file(str(translate_file)) or {}

    return {}

def save_namespace_translations(namespace: str, lang_code: str, translations: Dict[str, str]) -> bool:
    """ä¿å­˜æŒ‡å®šå‘½åç©ºé—´çš„ç¿»è¯‘åˆ°translateç›®å½•"""
    translate_dir = Path(TRANSLATE_DIR) / namespace / "lang"
    translate_dir.mkdir(parents=True, exist_ok=True)

    translate_file = translate_dir / f"{lang_code}.json"
    return save_json_file(str(translate_file), translations)

def find_existing_translations(lang_code: str) -> Dict[str, str]:
    """æŸ¥æ‰¾ç°æœ‰çš„ç¿»è¯‘æ–‡ä»¶"""
    existing_translations = {}

    # åŠ¨æ€æŸ¥æ‰¾assetsç›®å½•ä¸­çš„æ‰€æœ‰å‘½åç©ºé—´
    for namespace in get_namespace_list():
        namespace_translations = load_namespace_translations(namespace, lang_code)
        existing_translations.update(namespace_translations)

    return existing_translations

def get_context_for_keys(source_dict: Dict[str, str], target_keys: List[str], max_context: int = 10) -> Dict[str, str]:
    """ä¸ºç›®æ ‡é”®è·å–ä¸Šä¸‹æ–‡é”®å€¼å¯¹"""
    if len(target_keys) >= max_context:
        # å¦‚æœç›®æ ‡é”®æ•°é‡å·²ç»è¶…è¿‡æœ€å¤§ä¸Šä¸‹æ–‡æ•°ï¼Œç›´æ¥è¿”å›ç›®æ ‡é”®
        return {key: source_dict[key] for key in target_keys if key in source_dict}

    source_keys = list(source_dict.keys())
    target_set = set(target_keys)
    context_dict = {}

    # æ·»åŠ ç›®æ ‡é”®
    for key in target_keys:
        if key in source_dict:
            context_dict[key] = source_dict[key]

    # å¦‚æœç›®æ ‡é”®æ•°é‡å·²ç»è¾¾åˆ°ä¸Šä¸‹æ–‡é™åˆ¶ï¼Œç›´æ¥è¿”å›
    if len(context_dict) >= max_context:
        return context_dict

    # è®¡ç®—éœ€è¦æ·»åŠ çš„ä¸Šä¸‹æ–‡æ•°é‡
    needed_context = max_context - len(context_dict)

    # ä¸ºæ¯ä¸ªç›®æ ‡é”®æ®µè½æ·»åŠ ä¸Šä¸‹æ–‡
    segments = []
    current_segment = []

    # å°†è¿ç»­çš„ç›®æ ‡é”®åˆ†ç»„ä¸ºæ®µè½
    for i, key in enumerate(source_keys):
        if key in target_set:
            current_segment.append(i)
        else:
            if current_segment:
                segments.append(current_segment)
                current_segment = []

    if current_segment:
        segments.append(current_segment)

    # ä¸ºæ¯ä¸ªæ®µè½æ·»åŠ å‰åä¸Šä¸‹æ–‡
    context_indices = set()
    context_per_segment = max(1, needed_context // (len(segments) * 2)) if segments else 0

    for segment in segments:
        start_idx = segment[0]
        end_idx = segment[-1]

        # æ·»åŠ æ®µè½å‰çš„ä¸Šä¸‹æ–‡
        for i in range(max(0, start_idx - context_per_segment), start_idx):
            context_indices.add(i)

        # æ·»åŠ æ®µè½åçš„ä¸Šä¸‹æ–‡
        for i in range(end_idx + 1, min(len(source_keys), end_idx + 1 + context_per_segment)):
            context_indices.add(i)

    # å¦‚æœè¿˜éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡ï¼Œç»§ç»­æ‰©å±•
    remaining_needed = needed_context - len(context_indices)
    if remaining_needed > 0:
        for segment in segments:
            if remaining_needed <= 0:
                break
            start_idx = segment[0]
            end_idx = segment[-1]

            # ç»§ç»­å‘å‰æ‰©å±•
            for i in range(max(0, start_idx - context_per_segment - 1), max(0, start_idx - context_per_segment)):
                if remaining_needed <= 0:
                    break
                context_indices.add(i)
                remaining_needed -= 1

            # ç»§ç»­å‘åæ‰©å±•
            for i in range(min(len(source_keys), end_idx + 1 + context_per_segment),
                          min(len(source_keys), end_idx + 1 + context_per_segment + 1)):
                if remaining_needed <= 0:
                    break
                context_indices.add(i)
                remaining_needed -= 1

    # æ·»åŠ ä¸Šä¸‹æ–‡é”®åˆ°ç»“æœä¸­
    for idx in sorted(context_indices):
        key = source_keys[idx]
        if key not in context_dict and len(context_dict) < max_context:
            context_dict[key] = source_dict[key]

    return context_dict

def check_missing_translation_files() -> Dict[str, List[str]]:
    """æ£€æŸ¥ç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶

    Returns:
        Dict[namespace, List[missing_lang_codes]]: ç¼ºå¤±ç¿»è¯‘æ–‡ä»¶çš„å‘½åç©ºé—´å’Œè¯­è¨€ä»£ç 
    """
    missing_files = {}

    # è·å–æ‰€æœ‰å‘½åç©ºé—´
    namespaces = get_namespace_list()
    if not namespaces:
        return missing_files

    log_progress("æ£€æŸ¥ç¿»è¯‘æ–‡ä»¶å®Œæ•´æ€§...")

    for namespace in namespaces:
        # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        source_file = Path(ASSETS_DIR) / namespace / "lang" / "zh_cn.json"
        if not source_file.exists():
            continue

        missing_langs = []

        # æ£€æŸ¥æ¯ç§ç›®æ ‡è¯­è¨€çš„ç¿»è¯‘æ–‡ä»¶
        for lang_code, lang_name in TARGET_LANGUAGES.items():
            if lang_code == 'en_us':  # è·³è¿‡æºè¯­è¨€
                continue

            translate_file = Path(TRANSLATE_DIR) / namespace / "lang" / f"{lang_code}.json"
            if not translate_file.exists():
                missing_langs.append(lang_code)

        if missing_langs:
            missing_files[namespace] = missing_langs
            log_progress(f"  {namespace}: ç¼ºå¤± {len(missing_langs)} ä¸ªè¯­è¨€çš„ç¿»è¯‘æ–‡ä»¶")

    if missing_files:
        total_missing = sum(len(langs) for langs in missing_files.values())
        log_progress(f"å‘ç° {len(missing_files)} ä¸ªå‘½åç©ºé—´ç¼ºå¤±ç¿»è¯‘æ–‡ä»¶ï¼Œå…± {total_missing} ä¸ªæ–‡ä»¶")
    else:
        log_progress("æ‰€æœ‰ç¿»è¯‘æ–‡ä»¶å®Œæ•´")

    return missing_files

def create_virtual_changes_for_missing_files(missing_translations: Dict[str, List[str]]) -> List[FileChanges]:
    """ä¸ºç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶åˆ›å»ºè™šæ‹Ÿå˜æ›´

    Args:
        missing_translations: ç¼ºå¤±ç¿»è¯‘æ–‡ä»¶çš„å‘½åç©ºé—´å’Œè¯­è¨€ä»£ç 

    Returns:
        List[FileChanges]: è™šæ‹Ÿçš„æ–‡ä»¶å˜æ›´åˆ—è¡¨
    """
    virtual_changes = []

    for namespace, missing_langs in missing_translations.items():
        # åŠ è½½æºæ–‡ä»¶
        source_file = Path(ASSETS_DIR) / namespace / "lang" / "zh_cn.json"
        source_dict = load_json_file(str(source_file))
        if not source_dict:
            continue

        # åˆ›å»ºè™šæ‹Ÿå˜æ›´ï¼Œå°†æ‰€æœ‰æºæ–‡ä»¶çš„é”®æ ‡è®°ä¸ºæ–°å¢
        added_keys = [KeyChange(key=key, old_value=None, new_value=value, operation='added')
                     for key, value in source_dict.items()]

        virtual_change = FileChanges(
            namespace=namespace,
            file_path=str(source_file),
            added_keys=added_keys,
            deleted_keys=[],
            modified_keys=[]
        )

        virtual_changes.append(virtual_change)
        log_progress(f"  ä¸º {namespace} åˆ›å»ºè™šæ‹Ÿå˜æ›´ï¼ŒåŒ…å« {len(added_keys)} ä¸ªé”®")

    return virtual_changes

def check_missing_translation_files() -> List[Tuple[str, str]]:
    """æ£€æŸ¥ç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶

    Returns:
        List[Tuple[str, str]]: ç¼ºå¤±æ–‡ä»¶çš„ (namespace, lang_code) åˆ—è¡¨
    """
    missing_files = []

    # è·å–æ‰€æœ‰å‘½åç©ºé—´
    namespaces = get_namespace_list()

    for namespace in namespaces:
        # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        source_file = Path(ASSETS_DIR) / namespace / "lang" / "zh_cn.json"
        if not source_file.exists():
            continue

        # æ£€æŸ¥æ¯ç§ç›®æ ‡è¯­è¨€çš„ç¿»è¯‘æ–‡ä»¶
        for lang_code, _ in TARGET_LANGUAGES.items():
            if lang_code == 'zh_cn':  # è·³è¿‡æºè¯­è¨€
                continue

            translate_file = Path(TRANSLATE_DIR) / namespace / "lang" / f"{lang_code}.json"
            if not translate_file.exists():
                missing_files.append((namespace, lang_code))

    if missing_files:
        log_progress(f"å‘ç° {len(missing_files)} ä¸ªç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶")
        for namespace, lang_code in missing_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            log_progress(f"  ç¼ºå¤±: {namespace}/{lang_code}.json")
        if len(missing_files) > 5:
            log_progress(f"  ... è¿˜æœ‰ {len(missing_files) - 5} ä¸ªæ–‡ä»¶")

    return missing_files

def create_virtual_changes_for_missing_files(missing_files: List[Tuple[str, str]]) -> List[FileChanges]:
    """ä¸ºç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶åˆ›å»ºè™šæ‹Ÿå˜æ›´

    Args:
        missing_files: ç¼ºå¤±æ–‡ä»¶çš„ (namespace, lang_code) åˆ—è¡¨

    Returns:
        List[FileChanges]: è™šæ‹Ÿå˜æ›´åˆ—è¡¨
    """
    # æŒ‰å‘½åç©ºé—´åˆ†ç»„
    namespace_groups = {}
    for namespace, lang_code in missing_files:
        if namespace not in namespace_groups:
            namespace_groups[namespace] = []
        namespace_groups[namespace].append(lang_code)

    virtual_changes = []

    for namespace, lang_codes in namespace_groups.items():
        # åŠ è½½æºæ–‡ä»¶ä»¥è·å–æ‰€æœ‰é”®
        source_file = Path(ASSETS_DIR) / namespace / "lang" / "zh_cn.json"
        source_dict = load_json_file(str(source_file))
        if not source_dict:
            continue

        # åˆ›å»ºè™šæ‹Ÿå˜æ›´ï¼Œå°†æ‰€æœ‰é”®æ ‡è®°ä¸ºæ–°å¢
        added_keys = [KeyChange(key=key, old_value=None, new_value=value, operation='added')
                     for key, value in source_dict.items()]

        virtual_changes.append(FileChanges(
            namespace=namespace,
            file_path=str(source_file),
            added_keys=added_keys,
            deleted_keys=[],
            modified_keys=[]
        ))

        log_progress(f"ä¸ºå‘½åç©ºé—´ {namespace} åˆ›å»ºè™šæ‹Ÿå˜æ›´ï¼ŒåŒ…å« {len(added_keys)} ä¸ªé”®")

    return virtual_changes

def delete_keys_from_translations(namespace: str, keys_to_delete: List[str]) -> bool:
    """ä»æ‰€æœ‰ç¿»è¯‘æ–‡ä»¶ä¸­åˆ é™¤æŒ‡å®šçš„é”®"""
    success = True

    for lang_code, _ in TARGET_LANGUAGES.items():
        if lang_code == 'zh_cn':  # è·³è¿‡æºè¯­è¨€
            continue

        translate_file = Path(TRANSLATE_DIR) / namespace / "lang" / f"{lang_code}.json"
        if not translate_file.exists():
            continue

        # åŠ è½½ç°æœ‰ç¿»è¯‘
        translations = load_json_file(str(translate_file))
        if not translations:
            continue

        # åˆ é™¤æŒ‡å®šçš„é”®
        modified = False
        for key in keys_to_delete:
            if key in translations:
                del translations[key]
                modified = True

        # å¦‚æœæœ‰ä¿®æ”¹ï¼Œä¿å­˜æ–‡ä»¶
        if modified:
            if save_json_file(str(translate_file), translations):
                log_progress(f"    âœ“ ä» {lang_code} ç¿»è¯‘ä¸­åˆ é™¤äº† {len([k for k in keys_to_delete if k in translations])} ä¸ªé”®")
            else:
                log_progress(f"    âœ— åˆ é™¤é”®å¤±è´¥: {translate_file}", "error")
                success = False

    return success

def needs_translation(namespace: str, lang_code: str, source_dict: Dict[str, str]) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦ç¿»è¯‘"""
    force_translate = os.getenv('FORCE_TRANSLATE', 'false').lower() == 'true'

    if force_translate:
        return True

    # æ£€æŸ¥å·²æœ‰ç¿»è¯‘æ˜¯å¦å®Œæ•´
    existing_translations = load_namespace_translations(namespace, lang_code)

    # å¦‚æœæ²¡æœ‰ä»»ä½•ç¿»è¯‘ï¼Œéœ€è¦ç¿»è¯‘
    if not existing_translations:
        return True

    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„é”®éœ€è¦ç¿»è¯‘
    missing_keys = set(source_dict.keys()) - set(existing_translations.keys())
    if missing_keys:
        log_progress(f"{lang_code}: å‘ç° {len(missing_keys)} ä¸ªæ–°é”®éœ€è¦ç¿»è¯‘")
        return True

    return False

def main():
    """ä¸»å‡½æ•°"""
    log_section("ç¿»è¯‘è„šæœ¬å¯åŠ¨")

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv('DEEPSEEK_API_KEY')
    if not api_key:
        log_progress("é”™è¯¯ï¼šæœªæ‰¾åˆ°DEEPSEEK_API_KEYç¯å¢ƒå˜é‡", "error")
        sys.exit(1)

    log_progress("âœ“ APIå¯†é’¥å·²é…ç½®")

    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨éæ€è€ƒæ¨¡å¼
    non_thinking_mode = os.getenv('NON_THINKING_MODE', 'false').lower() == 'true'
    if non_thinking_mode:
        log_progress("âš¡ éæ€è€ƒæ¨¡å¼ï¼šä½¿ç”¨deepseek-chatæ¨¡å‹ä»¥æå‡é€Ÿåº¦")
    else:
        log_progress("ğŸ§  æ€è€ƒæ¨¡å¼ï¼šä½¿ç”¨deepseek-reasoneræ¨¡å‹ä»¥æå‡è´¨é‡")

    # åˆ›å»ºç¿»è¯‘å™¨
    translator = DeepSeekTranslator(api_key, non_thinking_mode)
    log_progress("âœ“ ç¿»è¯‘å™¨åˆå§‹åŒ–å®Œæˆ")

    # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ç¿»è¯‘
    force_translate = os.getenv('FORCE_TRANSLATE', 'false').lower() == 'true'

    if force_translate:
        log_progress("ğŸ”„ å¼ºåˆ¶ç¿»è¯‘æ¨¡å¼ï¼šå°†é‡æ–°ç¿»è¯‘æ‰€æœ‰å†…å®¹")
        # ä½¿ç”¨åŸæœ‰çš„å…¨é‡ç¿»è¯‘é€»è¾‘
        run_full_translation(translator)
    else:
        log_progress("ğŸ” æ™ºèƒ½ç¿»è¯‘æ¨¡å¼ï¼šæ£€æµ‹Gitå˜æ›´")
        # ä½¿ç”¨æ–°çš„æ™ºèƒ½å·®å¼‚ç¿»è¯‘é€»è¾‘
        run_smart_translation(translator)

def run_full_translation(translator):
    """è¿è¡Œå…¨é‡ç¿»è¯‘ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
    # è·å–æ‰€æœ‰å‘½åç©ºé—´
    log_progress("æ‰«æå‘½åç©ºé—´...")
    namespaces = get_namespace_list()
    if not namespaces:
        log_progress("é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•å‘½åç©ºé—´", "error")
        sys.exit(1)

    log_progress(f"âœ“ æ‰¾åˆ° {len(namespaces)} ä¸ªå‘½åç©ºé—´: {', '.join(namespaces)}")
    # è®¡ç®—å®é™…éœ€è¦ç¿»è¯‘çš„è¯­è¨€æ•°ï¼ˆTARGET_LANGUAGESå·²æ’é™¤æºè¯­è¨€zh_cnï¼‰
    target_lang_count = len(TARGET_LANGUAGES)
    log_progress(f"âœ“ ç›®æ ‡è¯­è¨€: {target_lang_count} ç§")

    # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
    progress_tracker = ProgressTracker(target_lang_count, len(namespaces))

    log_section_end()

    # è°ƒç”¨åŸæœ‰çš„ç¿»è¯‘é€»è¾‘
    continue_full_translation(translator, progress_tracker, namespaces)

def run_smart_translation(translator):
    """è¿è¡Œæ™ºèƒ½å·®å¼‚ç¿»è¯‘"""
    # æ£€æµ‹Gitå˜æ›´
    file_changes = get_git_changes()

    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶ç¼ºå¤±æƒ…å†µ
    missing_translations = check_missing_translation_files()

    if not file_changes and not missing_translations:
        log_progress("æœªæ£€æµ‹åˆ°æºç¿»è¯‘æ–‡ä»¶å˜æ›´ï¼Œä¸”æ‰€æœ‰ç¿»è¯‘æ–‡ä»¶å®Œæ•´ï¼Œè·³è¿‡ç¿»è¯‘")
        return

    if not file_changes and missing_translations:
        log_progress("æœªæ£€æµ‹åˆ°æºæ–‡ä»¶å˜æ›´ï¼Œä½†å‘ç°ç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶ï¼Œå°†è¡¥å……ç¿»è¯‘")
        # ä¸ºç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶åˆ›å»ºè™šæ‹Ÿå˜æ›´
        file_changes = create_virtual_changes_for_missing_files(missing_translations)

    log_progress(f"æ£€æµ‹åˆ° {len(file_changes)} ä¸ªå‘½åç©ºé—´æœ‰å˜æ›´")

    # å¤„ç†æ¯ä¸ªæœ‰å˜æ›´çš„å‘½åç©ºé—´
    for changes in file_changes:
        log_section(f"å¤„ç†å‘½åç©ºé—´: {changes.namespace}")

        # é¦–å…ˆå¤„ç†åˆ é™¤çš„é”®
        if changes.deleted_keys:
            deleted_key_names = [change.key for change in changes.deleted_keys]
            log_progress(f"åˆ é™¤ {len(deleted_key_names)} ä¸ªé”®: {', '.join(deleted_key_names[:5])}{'...' if len(deleted_key_names) > 5 else ''}")
            delete_keys_from_translations(changes.namespace, deleted_key_names)

        # å¤„ç†æ·»åŠ å’Œä¿®æ”¹çš„é”®ï¼ˆè§†ä¸ºæ·»åŠ ï¼‰
        added_and_modified = changes.added_keys + changes.modified_keys
        if not added_and_modified:
            log_progress("æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„æ–°å¢æˆ–ä¿®æ”¹å†…å®¹")
            continue

        # åŠ è½½æºæ–‡ä»¶
        source_file = Path(ASSETS_DIR) / changes.namespace / "lang" / "en_us.json"
        source_dict = load_json_file(str(source_file))
        if not source_dict:
            log_progress(f"æ— æ³•åŠ è½½æºæ–‡ä»¶: {source_file}", "error")
            continue

        # è·å–éœ€è¦ç¿»è¯‘çš„é”®
        keys_to_translate = [change.key for change in added_and_modified]
        log_progress(f"éœ€è¦ç¿»è¯‘ {len(keys_to_translate)} ä¸ªé”®")

        # è·å–ç¿»è¯‘ä¸Šä¸‹æ–‡
        context_dict = get_context_for_keys(source_dict, keys_to_translate, max_context=10)
        log_progress(f"ç¿»è¯‘ä¸Šä¸‹æ–‡åŒ…å« {len(context_dict)} ä¸ªé”®å€¼å¯¹")

        # ç¿»è¯‘åˆ°å„ç§ç›®æ ‡è¯­è¨€
        for lang_code, lang_name in TARGET_LANGUAGES.items():
            if lang_code == 'zh_cn':  # è·³è¿‡æºè¯­è¨€
                continue

            log_progress(f"  ç¿»è¯‘åˆ° {lang_name} ({lang_code})")

            # ç¿»è¯‘ä¸Šä¸‹æ–‡
            translated_context = translator.translate_batch(context_dict, lang_code, lang_name)
            if not translated_context:
                log_progress(f"    âœ— ç¿»è¯‘å¤±è´¥", "error")
                continue

            # åŠ è½½ç°æœ‰ç¿»è¯‘
            existing_translations = load_namespace_translations(changes.namespace, lang_code)

            # åªä¿å­˜ç›®æ ‡é”®çš„ç¿»è¯‘ï¼ˆä¸åŒ…æ‹¬ä¸Šä¸‹æ–‡ï¼‰
            target_translations = {key: translated_context[key]
                                 for key in keys_to_translate
                                 if key in translated_context}

            # åˆå¹¶ç¿»è¯‘ç»“æœ
            final_translations = existing_translations.copy()
            final_translations.update(target_translations)

            # ä¿å­˜ç¿»è¯‘ç»“æœ
            if save_namespace_translations(changes.namespace, lang_code, final_translations):
                log_progress(f"    âœ“ æˆåŠŸç¿»è¯‘ {len(target_translations)} ä¸ªé”®")
            else:
                log_progress(f"    âœ— ä¿å­˜ç¿»è¯‘å¤±è´¥", "error")

        log_section_end()

    log_section("æ™ºèƒ½ç¿»è¯‘å®Œæˆ")
    log_progress("ğŸ‰ æ‰€æœ‰å˜æ›´å·²å¤„ç†å®Œæˆï¼")
    log_section_end()

def continue_full_translation(translator, progress_tracker, namespaces):
    """ç»§ç»­æ‰§è¡Œå…¨é‡ç¿»è¯‘çš„å‰©ä½™é€»è¾‘"""
    # å¤„ç†æ¯ç§ç›®æ ‡è¯­è¨€
    for lang_code, lang_name in TARGET_LANGUAGES.items():
        if lang_code == 'zh_cn':  # è·³è¿‡æºè¯­è¨€
            continue

        progress_tracker.start_language(lang_code, lang_name)

        # å¤„ç†æ¯ä¸ªå‘½åç©ºé—´
        for namespace in namespaces:
            progress_tracker.start_namespace(namespace)

            # åŠ è½½è¯¥å‘½åç©ºé—´çš„æºè¯­è¨€æ–‡ä»¶ï¼ˆzh_cnï¼‰
            source_file = Path(ASSETS_DIR) / namespace / "lang" / "zh_cn.json"
            if not source_file.exists():
                log_progress(f"    è·³è¿‡ï¼šæºæ–‡ä»¶ä¸å­˜åœ¨ {source_file}", "warning")
                continue

            source_dict = load_json_file(str(source_file))
            if not source_dict:
                log_progress(f"    è·³è¿‡ï¼šæ— æ³•åŠ è½½æºæ–‡ä»¶ {source_file}", "warning")
                continue

            log_progress(f"    âœ“ åŠ è½½æºæ–‡ä»¶æˆåŠŸï¼Œå…± {len(source_dict)} ä¸ªé”®")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¿»è¯‘
            if not needs_translation(namespace, lang_code, source_dict):
                log_progress(f"    è·³è¿‡ï¼šæ— éœ€ç¿»è¯‘")
                continue

            # åŠ è½½è¯¥å‘½åç©ºé—´å·²æœ‰çš„ç¿»è¯‘
            log_progress(f"    åŠ è½½å·²æœ‰ç¿»è¯‘...")
            existing_translate = load_namespace_translations(namespace, lang_code)
            log_progress(f"    âœ“ å·²æœ‰ç¿»è¯‘ï¼š{len(existing_translate)} ä¸ªé”®")

            # ç¡®å®šéœ€è¦ç¿»è¯‘çš„å†…å®¹
            force_translate = os.getenv('FORCE_TRANSLATE', 'false').lower() == 'true'
            keys_to_translate = {}

            if force_translate:
                # å¼ºåˆ¶ç¿»è¯‘æ¨¡å¼ï¼šç¿»è¯‘æ‰€æœ‰é”®
                keys_to_translate = source_dict.copy()
                log_progress(f"    å¼ºåˆ¶ç¿»è¯‘æ¨¡å¼ï¼šå°†é‡æ–°ç¿»è¯‘æ‰€æœ‰ {len(keys_to_translate)} ä¸ªé”®")
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šåªç¿»è¯‘ç¼ºå¤±çš„é”®
                for key, value in source_dict.items():
                    if key not in existing_translate:
                        keys_to_translate[key] = value

            if not keys_to_translate:
                log_progress(f"    æ‰€æœ‰å†…å®¹å·²ç¿»è¯‘å®Œæˆ")
                continue

            log_progress(f"    éœ€è¦ç¿»è¯‘ {len(keys_to_translate)} ä¸ªæ–°é”®")

            # åˆ†æ‰¹ç¿»è¯‘ï¼ˆæ¯æ¬¡æœ€å¤š40ä¸ªé”®ï¼Œé¿å…è¯·æ±‚è¿‡å¤§ï¼‰
            batch_size = 40
            if force_translate:
                # å¼ºåˆ¶ç¿»è¯‘æ¨¡å¼ï¼šä»ç©ºå­—å…¸å¼€å§‹ï¼Œå®Œå…¨æ›¿æ¢
                all_translated = {}
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šåŸºäºç°æœ‰ç¿»è¯‘è¿›è¡Œå¢é‡æ›´æ–°
                all_translated = existing_translate.copy()

            keys_list = list(keys_to_translate.items())
            total_batches = (len(keys_list) + batch_size - 1) // batch_size
            log_progress(f"    å¼€å§‹åˆ†æ‰¹ç¿»è¯‘ï¼Œå…± {total_batches} æ‰¹ï¼Œæ¯æ‰¹æœ€å¤š {batch_size} ä¸ªé”®")

            successful_translations = 0
            for i in range(0, len(keys_list), batch_size):
                batch = dict(keys_list[i:i + batch_size])
                batch_num = i//batch_size + 1
                progress_tracker.log_batch_progress(batch_num, total_batches, len(batch))

                translated_batch = translator.translate_batch(batch, lang_code, lang_name)
                if translated_batch:
                    all_translated.update(translated_batch)
                    successful_translations += len(translated_batch)
                    log_progress(f"      âœ“ æ‰¹æ¬¡ {batch_num} æˆåŠŸç¿»è¯‘ {len(translated_batch)} ä¸ªé”®")
                    flush_logs()  # ç¡®ä¿ç¿»è¯‘è¿›åº¦è¢«åŠæ—¶å†™å…¥æ—¥å¿—
                else:
                    log_progress(f"      âœ— æ‰¹æ¬¡ {batch_num} ç¿»è¯‘å¤±è´¥", "error")
                    flush_logs()  # ç¡®ä¿é”™è¯¯ä¿¡æ¯è¢«åŠæ—¶å†™å…¥æ—¥å¿—

            # ä¿å­˜ç¿»è¯‘ç»“æœåˆ°å¯¹åº”çš„å‘½åç©ºé—´ç›®å½•
            log_progress(f"    ä¿å­˜ç¿»è¯‘ç»“æœ...")
            if save_namespace_translations(namespace, lang_code, all_translated):
                log_progress(f"    âœ“ ä¿å­˜æˆåŠŸ: {TRANSLATE_DIR}/{namespace}/lang/{lang_code}.json")
                if force_translate:
                    log_progress(f"    âœ“ å¼ºåˆ¶ç¿»è¯‘å®Œæˆï¼šé‡æ–°ç¿»è¯‘äº† {successful_translations} ä¸ªé”®ï¼Œæ–‡ä»¶åŒ…å« {len(all_translated)} ä¸ªé”®")
                else:
                    log_progress(f"    âœ“ æ€»è®¡ç¿»è¯‘ {successful_translations} ä¸ªæ–°é”®ï¼Œæ–‡ä»¶åŒ…å« {len(all_translated)} ä¸ªé”®")
            else:
                log_progress(f"    âœ— ä¿å­˜å¤±è´¥: {TRANSLATE_DIR}/{namespace}/lang/{lang_code}.json", "error")

            log_progress(progress_tracker.get_total_progress())

        progress_tracker.finish_language()

    log_section("ç¿»è¯‘å®Œæˆ")
    log_progress("ğŸ‰ æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡å·²å®Œæˆï¼")
    log_section_end()
    
    # ç¡®ä¿æ‰€æœ‰æ—¥å¿—éƒ½è¢«å†™å…¥æ–‡ä»¶
    flush_logs()

if __name__ == "__main__":
    try:
        main()
    finally:
        # ç¡®ä¿æ—¥å¿—æ–‡ä»¶è¢«æ­£ç¡®å…³é—­
        flush_logs()
        close_logs()
